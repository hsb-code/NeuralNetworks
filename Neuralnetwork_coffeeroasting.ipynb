{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Installing Tensorflow\n"
      ],
      "metadata": {
        "id": "GBMeuNPfniZ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install numpy"
      ],
      "metadata": {
        "id": "3GRr4aRsqfoS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install tensorflow==2"
      ],
      "metadata": {
        "id": "3cRtG1B_rkdY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install tensorflow==2.14.0"
      ],
      "metadata": {
        "id": "Se8TBQLtr9aW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Connect G-Drive"
      ],
      "metadata": {
        "id": "taXVR1UdWA8U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('gdrive')"
      ],
      "metadata": {
        "id": "Mn1lQtL2s5qe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Libraries"
      ],
      "metadata": {
        "id": "TMyje5HdWKk-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import keras as kr\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense"
      ],
      "metadata": {
        "id": "BNteFirahNcd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training Dataset"
      ],
      "metadata": {
        "id": "9dBN7GtHkEsa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input = [[185.32 ,12.69], [259.92 , 11.87], [231.01 , 14.41], [175.37 , 11.72],\n",
        "[187.12 , 14.13] ,[225.91 , 12.1 ], [208.41 , 14.18],\n",
        "[207.08 , 14.03], [280.6 ,  14.23], [202.87 , 12.25]]\n",
        "\n",
        "X = np.array(input)\n",
        "\n",
        "output = [[1.], [0.], [0.], [0.], [1.], [1.], [0.], [0.], [0.], [1.]]\n",
        "\n",
        "y_train = np.array(output)"
      ],
      "metadata": {
        "id": "iuwKbe44kMOk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rezlvDZRw2tO",
        "outputId": "f0b05d2b-9be7-482c-8677-11186b7d5968"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sxMpf4OaxAo3",
        "outputId": "d288dc56-2ae0-4c51-8e63-32d7665b9849"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Normalizing"
      ],
      "metadata": {
        "id": "TxrIBFm7me0G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalization in Keras and TensorFlow refers to the process of scaling and centering input\n",
        "# data to make it suitable for training machine learning models."
      ],
      "metadata": {
        "id": "5f1TbNdXqQYo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Temperature max and min before normalizaton, col0: {np.max(X[:, 0])} & {np.min(X[:, 0])}' )\n",
        "print(f'Duration max and min before normalizaton, col1: {np.max(X[:, 1])} & {np.min(X[:, 1])}' )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NMVDG64Ely2B",
        "outputId": "8e0baa1a-4b1c-4ff6-a409-2097db372103"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Temperature max and min before normalizaton, col0: 280.6 & 175.37\n",
            "Duration max and min before normalizaton, col1: 14.41 & 11.72\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "normal = tf.keras.layers.Normalization(axis=-1)\n",
        "normal.adapt(X) # calculate and set"
      ],
      "metadata": {
        "id": "p6VFNZZYmFNi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tf.keras.layers.Normalization: This is a class in TensorFlow's Keras library that represents a normalization layer#.\n",
        "# It's used for normalizing input data before feeding it into a neural network.\n",
        "\n",
        "# The line of code norm_l.adapt(X) is used to adapt (calculate and set) the normalization parameters of\n",
        "# the Normalization layer (norm_l) based on the input data X. Specifically, it computes the mean and variance\n",
        "# of the data in order to standardize (normalize) the input during training and later inference."
      ],
      "metadata": {
        "id": "wEN5lBKbrIHM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_norm = normal(X)"
      ],
      "metadata": {
        "id": "PI0WeqtjqEOV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Temperature max and min after normalizaton, col0: {np.max(X_norm[:, 0]):0.2f} & {np.min(X_norm[:, 0]):0.2f}' )\n",
        "print(f'Duration max and min after normalizaton, col1: {np.max(X_norm[:, 1]):0.2f} & {np.min(X_norm[:, 1]):0.2f}' )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WMAnWlPEqLoW",
        "outputId": "71c56ab4-6b71-4c79-e312-b921bd4d34e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Temperature max and min after normalizaton, col0: 2.02 & -1.29\n",
            "Duration max and min after normalizaton, col1: 1.17 & -1.35\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Tiling"
      ],
      "metadata": {
        "id": "umH0TlRHWzQK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Tiling data in NumPy can be a useful technique for increasing your dataset size by\n",
        "# generating additional training examples through data augmentation. Data augmentation involves\n",
        "# applying random transformations to the original data, such as rotations, translations, or flips,\n",
        "# to create new, slightly modified samples. This can help improve the generalization of machine learning models.\n",
        "\n"
      ],
      "metadata": {
        "id": "0UUegrjEX4lJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Xt = np.tile(X_norm,(1000,1))\n",
        "Yt= np.tile(y_train,(1000,1))\n",
        "print(Xt.shape, Yt.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PO1G-tfZsVgx",
        "outputId": "b196bf76-8630-4eef-a221-796476c97650"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10000, 2) (10000, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tensorflow Model"
      ],
      "metadata": {
        "id": "p26615LCW4Mp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(1234)\n",
        "model = Sequential(\n",
        "    [\n",
        "        tf.keras.Input(shape = (2,)), # input data should be 1D array with 2 elements\n",
        "        Dense(3, activation= 'sigmoid', name = 'layer1'), # neurons, activation, name\n",
        "        Dense(1, activation= 'sigmoid', name = 'layer2'),\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "05XlADxlw8sr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tf.random.set.seed(1234) it's essential to set the seed before any random operations occur in your code to guarantee reproducibility."
      ],
      "metadata": {
        "id": "53EFQQIP0__Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3uaTlPK0zWKl",
        "outputId": "a6b500a9-e1fe-4a63-c4b2-cc21116ca0a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " layer1 (Dense)              (None, 3)                 9         \n",
            "                                                                 \n",
            " layer2 (Dense)              (None, 1)                 4         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 13 (52.00 Byte)\n",
            "Trainable params: 13 (52.00 Byte)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# WB Parameters"
      ],
      "metadata": {
        "id": "8RuHyH6EXDum"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "L1_num_params = 2 * 3 + 3   # W1 parameters  + b1 parameters\n",
        "L2_num_params = 3 * 1 + 1   # W2 parameters  + b2 parameters\n",
        "print(\"L1 params = \", L1_num_params, \", L2 params = \", L2_num_params  )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ysActgwQzg-8",
        "outputId": "af0662d7-9a2b-44e2-ca46-57afc94fe939"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "L1 params =  9 , L2 params =  4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# L1_num_params = 2 features in previous layer, 3 neurons in current layer, 3 bias for current layer (each for one neuron)\n",
        "# same follows for L2_num_params"
      ],
      "metadata": {
        "id": "oi3kNIP00-cB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w1, b1 = model.get_layer('layer1'). get_weights()\n",
        "w2, b2 = model.get_layer('layer2'). get_weights()"
      ],
      "metadata": {
        "id": "nTeepLAG2Gbw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'w1{w1.shape}: {w1} & b1{b1.shape}: {b1}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sRZ8ET7Tqvut",
        "outputId": "b34bc573-a457-470b-86ca-b5ac1dcb52ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "w1(2, 3): [[-1.0760597  -0.6619935  -0.67265666]\n",
            " [ 0.42656064 -0.7484767  -0.3359921 ]] & b1(3,): [0. 0. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'w2{w2.shape}: {w2} & b2{b2.shape}: {b2}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hRfNHMyWrjAR",
        "outputId": "e81f5269-c627-4364-8075-40cf45f224fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "w2(3, 1): [[ 0.00781107]\n",
            " [ 0.225497  ]\n",
            " [-0.73969084]] & b2(1,): [0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training Model"
      ],
      "metadata": {
        "id": "77I-D3uVXHtG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    loss = tf.keras.losses.BinaryCrossentropy(),\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.01),\n",
        ")\n",
        "\n",
        "model.fit(\n",
        "    Xt,Yt,\n",
        "    epochs=10,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Drb0dw-ErtiZ",
        "outputId": "e4073d02-54ae-463e-9b9e-4ac9fa225f26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.5086\n",
            "Epoch 2/10\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.3267\n",
            "Epoch 3/10\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.2494\n",
            "Epoch 4/10\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.1590\n",
            "Epoch 5/10\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0789\n",
            "Epoch 6/10\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0443\n",
            "Epoch 7/10\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0283\n",
            "Epoch 8/10\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0196\n",
            "Epoch 9/10\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0143\n",
            "Epoch 10/10\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0108\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7b5b0be010c0>"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model.compile: This function is used to configure the training process of your model.\n",
        "# It specifies the loss function, optimizer, and any optional metrics you want to track during training."
      ],
      "metadata": {
        "id": "19o3kq0jsKNO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loss=tf.keras.losses.BinaryCrossentropy(): This sets the loss function for your model to binary\n",
        "# cross-entropy. Binary cross-entropy is commonly used as the loss function for binary classification problems,\n",
        "# where the goal is to classify inputs into one of two classes (0 or 1)"
      ],
      "metadata": {
        "id": "rIj-lSoeuePU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# optimizer=tf.keras.optimizers.Adam(learning_rate=0.01): This sets the optimizer for your model to the Adam optimizer\n",
        "# with a learning rate of 0.01. The optimizer is responsible for updating the model's weights during training\n",
        "# to minimize the specified loss function."
      ],
      "metadata": {
        "id": "i_BUyHHaulrm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model.fit: This function is used to train your model on a given dataset"
      ],
      "metadata": {
        "id": "dVD2FxgvusK3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# epochs=10: This specifies the number of training epochs, which is the number of times the model will\n",
        "# go through the entire dataset during training"
      ],
      "metadata": {
        "id": "qBLvm1DguwDh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Updating WB"
      ],
      "metadata": {
        "id": "p9shRbFoXRhU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "W1, b1 = model.get_layer(\"layer1\").get_weights()\n",
        "W2, b2 = model.get_layer(\"layer2\").get_weights()\n",
        "print(\"W1:\\n\", W1, \"\\nb1:\", b1)\n",
        "print(\"W2:\\n\", W2, \"\\nb2:\", b2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DtUgzI5Fu1Hk",
        "outputId": "7dd4aa63-3fef-4839-f178-9665e41e9f8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "W1:\n",
            " [[-10.958701   -8.919246   -3.1542132]\n",
            " [ -7.52236    -6.294144   -3.9728174]] \n",
            "b1: [-0.089944    0.01721847 -6.8249526 ]\n",
            "W2:\n",
            " [[ 5.578443 ]\n",
            " [ 5.2804027]\n",
            " [-9.769765 ]] \n",
            "b2: [-5.3986807]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prediction Testing"
      ],
      "metadata": {
        "id": "C1BGKJWgXUWi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = np.array([\n",
        "    [259,11],  # postive example\n",
        "    [185,12]])   # negative example\n",
        "X_testn = normal(X_test)\n",
        "predictions = model.predict(X_testn)\n",
        "print(\"predictions = \\n\", predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wqq6DavLzP-F",
        "outputId": "3152108d-fc80-44ae-b412-762c8757bbc4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 61ms/step\n",
            "predictions = \n",
            " [[0.78761667]\n",
            " [0.29675195]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "yhat = np.zeros_like(predictions) # : This line initializes an array yhat with the same shape as predictions array but filled with zeros.\n",
        "for i in range(len(predictions)):\n",
        "    if predictions[i] >= 0.5:\n",
        "        yhat[i] = 1\n",
        "    else:\n",
        "        yhat[i] = 0\n",
        "print(f\"decisions = \\n{yhat}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Vi3bZmrza66",
        "outputId": "c2834981-9e89-4226-f9f6-14a9f220a14e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "decisions = \n",
            "[[1.]\n",
            " [0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "yhat = (predictions >= 0.5).astype(int)\n",
        "print(f\"decisions = \\n{yhat}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OVnBrcb5zeyF",
        "outputId": "ebbd721b-b4bb-47f3-e37b-3280ee7f5fbe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "decisions = \n",
            "[[1]\n",
            " [0]]\n"
          ]
        }
      ]
    }
  ]
}